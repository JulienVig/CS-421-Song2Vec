{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turned-majority",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T16:56:49.229666Z",
     "start_time": "2021-05-16T16:56:46.248056Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from utils import read_lastfm\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-national",
   "metadata": {},
   "source": [
    "# Song2vec loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interstate-complexity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T16:56:49.243990Z",
     "start_time": "2021-05-16T16:56:49.235486Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_vocab(model):\n",
    "    emb_vectors = {}\n",
    "    for n in model.wv.index_to_key:\n",
    "        emb_vectors[n] = model.wv[n]\n",
    "    return emb_vectors\n",
    "\n",
    "def load_model(filename):\n",
    "    model = Word2Vec.load(filename)\n",
    "    emb_vectors = build_vocab(model)\n",
    "    return emb_vectors, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "placed-arena",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T16:57:39.248856Z",
     "start_time": "2021-05-16T16:56:49.267204Z"
    }
   },
   "outputs": [],
   "source": [
    "emb_vectors, model = load_model(\"data/word2vec/word2vec.model\")\n",
    "s2v_df = pd.DataFrame(data=emb_vectors.values(), index=emb_vectors.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-celebrity",
   "metadata": {},
   "source": [
    "# TF-IDF initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proper-netherlands",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:00:39.517254Z",
     "start_time": "2021-05-16T16:57:39.256505Z"
    }
   },
   "outputs": [],
   "source": [
    "songs, users = read_lastfm(zip_name=\"data/lastfm-dataset-1K.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impressive-courage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:00:41.213523Z",
     "start_time": "2021-05-16T17:00:39.524959Z"
    }
   },
   "outputs": [],
   "source": [
    "songs[\"song_id\"]= songs.artist_name.cat.codes.astype(\"int64\") * songs.track_name.nunique() \\\n",
    "                            + songs.track_name.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "close-albania",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:11.888521Z",
     "start_time": "2021-05-16T17:00:41.217304Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_df = songs.sort_values([\"user_id\", \"timestamp\"]).groupby(\"user_id\")\\\n",
    "                .agg(sequence=(\"song_id\", list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "documentary-sacramento",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:11.895471Z",
     "start_time": "2021-05-16T17:01:11.890817Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = corpus_df.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interested-sterling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:26.520046Z",
     "start_time": "2021-05-16T17:01:11.898497Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "differential-local",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:26.534945Z",
     "start_time": "2021-05-16T17:01:26.522347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 1498727)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "clear-discipline",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:26.582616Z",
     "start_time": "2021-05-16T17:01:26.577033Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_song_vector(song_id, X, vectorizer):\n",
    "    idx = vectorizer.vocabulary_[song_id]\n",
    "    return X[:, idx].toarray()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "attached-humor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:26.625105Z",
     "start_time": "2021-05-16T17:01:26.587874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01709776, 0.        , 0.        , 0.02194015, 0.        ,\n",
       "       0.00360557, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_song_vector(3583077562, X, vectorizer)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reasonable-subcommittee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:26.774433Z",
     "start_time": "2021-05-16T17:01:26.631091Z"
    }
   },
   "outputs": [],
   "source": [
    "song_ids = list(vectorizer.vocabulary_.keys())\n",
    "indices = list(vectorizer.vocabulary_.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "latin-county",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:29.638086Z",
     "start_time": "2021-05-16T17:01:26.784803Z"
    }
   },
   "outputs": [],
   "source": [
    "song_ids = [x for _,x in sorted(zip(indices,song_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "independent-struggle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:33.263449Z",
     "start_time": "2021-05-16T17:01:29.640969Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(data=X.T.todense(), index=song_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-parameter",
   "metadata": {},
   "source": [
    "# Classification Tasks\n",
    "\n",
    "* Predict if two songs appear in the same context\n",
    "* Predict if two songs are from the same artist\n",
    "* Predict the tag of a song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raising-deputy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:51.888863Z",
     "start_time": "2021-05-16T17:01:51.878900Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accurate-gabriel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:53.735946Z",
     "start_time": "2021-05-16T17:01:53.717277Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(y_test, y_pred, y_proba):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    return acc, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ongoing-vitamin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T20:50:36.831435Z",
     "start_time": "2021-05-16T20:50:36.805906Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_RF(X_train, X_test, y_train, y_test, \n",
    "               param_grid = {'n_estimators': [2, 50 ,100, 150],\n",
    "                      'criterion': ['gini', 'entropy']}):    \n",
    "    model = RandomForestClassifier(random_state=SEED)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    print(\"Starting Grid search\")\n",
    "    grid = GridSearchCV(model, param_grid, cv=cv, scoring='f1', verbose=4)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    print(f\"Best parameters are: {grid.best_params_}\")\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    return compute_metrics(y_test, y_pred, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "conventional-publisher",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:55.713453Z",
     "start_time": "2021-05-16T17:01:55.696365Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_random(X_train, y_train, X_test, y_test):\n",
    "    random = DummyClassifier(strategy='uniform', random_state=SEED)\n",
    "    random.fit(X_train, y_train)\n",
    "    y_pred = random.predict(X_test)\n",
    "    y_proba = random.predict_proba(X_test)[:, 1]\n",
    "    return compute_metrics(y_test, y_pred, y_proba)\n",
    "\n",
    "def predict_majority(X_train, y_train, X_test, y_test):\n",
    "    majority = DummyClassifier(strategy='most_frequent', random_state=SEED)\n",
    "    majority.fit(X_train, y_train)\n",
    "    y_pred = majority.predict(X_test)\n",
    "    y_proba = majority.predict_proba(X_test)[:, 1]\n",
    "    return compute_metrics(y_test, y_pred, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excess-jurisdiction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:01:58.337745Z",
     "start_time": "2021-05-16T17:01:58.311531Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vectors_pairs(vectors, song_pairs):\n",
    "    vector_pairs = vectors.merge(song_pairs, right_on=\"song1\", left_index=True)\\\n",
    "            .merge(vectors, left_on=\"song2\", right_index=True)\\\n",
    "            .drop(['song1', 'song2'], axis=1)\n",
    "    print(len(vector_pairs))\n",
    "    print(len(song_pairs))\n",
    "    assert len(vector_pairs) == len(song_pairs)\n",
    "    assert vector_pairs.shape[1] == vectors.shape[1] * 2\n",
    "    return vector_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-greek",
   "metadata": {},
   "source": [
    "## Same context classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "jewish-fields",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:02:29.830271Z",
     "start_time": "2021-05-16T21:01:54.051902Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_songs = songs.sort_values([\"user_id\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "brief-omega",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:02:29.890614Z",
     "start_time": "2021-05-16T21:02:29.838001Z"
    }
   },
   "outputs": [],
   "source": [
    "def pick_song_in_same_context(songs, half_n):\n",
    "    \"\"\"Simply chooses random songs pair them with the previous or following one\"\"\"\n",
    "    np.random.seed(SEED)\n",
    "    idx1 = np.random.randint(1, len(songs) - 1, half_n) #Exclude first and last song\n",
    "    idx2 = idx1.copy() #Offset the first index by -1 or 1 \n",
    "    idx2[::2] += 1\n",
    "    idx2[1::2] -= 1\n",
    "    songs1 = songs.iloc[idx1].song_id.values\n",
    "    songs2 = songs.iloc[idx2].song_id.values\n",
    "    X = np.c_[songs1, songs2]\n",
    "    y = np.ones(half_n)\n",
    "    return X, y\n",
    "    \n",
    "def pick_songs_in_diff_context(songs, half_n):\n",
    "    songs1 = songs.sample(half_n, random_state=SEED).song_id.values\n",
    "    songs2 = songs.sample(half_n, random_state=SEED + 1).song_id.values\n",
    "    X = np.c_[songs1, songs2]\n",
    "    y = np.zeros(half_n)\n",
    "    return X, y\n",
    "\n",
    "def create_context_dataset(sorted_songs, n=20000):\n",
    "    \"\"\"Create a dataset of song pairs that either appeared in the same context or not\"\"\" \n",
    "    X_pos, y_pos = pick_song_in_same_context(sorted_songs, n//2)\n",
    "    X_neg, y_neg = pick_songs_in_diff_context(sorted_songs, n//2)\n",
    "    old_X = np.r_[X_pos, X_neg]\n",
    "    old_y = np.r_[y_pos, y_neg]\n",
    "    dataset = list(zip(old_X, old_y))\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(dataset)\n",
    "    X, y = zip(*dataset)\n",
    "    return pd.DataFrame(X, columns=[\"song1\", \"song2\"]), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "changing-friendly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:02:33.466829Z",
     "start_time": "2021-05-16T21:02:29.896383Z"
    }
   },
   "outputs": [],
   "source": [
    "song_pairs, labels = create_context_dataset(sorted_songs, n= 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "solid-infection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:02:33.623095Z",
     "start_time": "2021-05-16T21:02:33.469617Z"
    }
   },
   "outputs": [],
   "source": [
    "#Only keep song with s2v embeddings\n",
    "song_pairs = song_pairs.copy()\n",
    "song_pairs['labels'] = labels\n",
    "song_pairs = song_pairs[song_pairs.song1.isin(s2v_df.index) & song_pairs.song2.isin(s2v_df.index)]\n",
    "labels = song_pairs.labels\n",
    "song_pairs.drop('labels', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-tragedy",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "incorporated-stuart",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T07:17:32.275768Z",
     "start_time": "2021-05-17T07:17:10.192688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8485\n",
      "8485\n"
     ]
    }
   ],
   "source": [
    "tfidf_pairs = create_vectors_pairs(tfidf_df, song_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cosmetic-syndicate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T07:17:32.341273Z",
     "start_time": "2021-05-17T07:17:32.283334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>9_x</th>\n",
       "      <th>...</th>\n",
       "      <th>982_y</th>\n",
       "      <th>983_y</th>\n",
       "      <th>984_y</th>\n",
       "      <th>985_y</th>\n",
       "      <th>986_y</th>\n",
       "      <th>987_y</th>\n",
       "      <th>988_y</th>\n",
       "      <th>989_y</th>\n",
       "      <th>990_y</th>\n",
       "      <th>991_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8584</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9648</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1984 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0_x       1_x  2_x       3_x  4_x  5_x  6_x  7_x  8_x  9_x  ...  \\\n",
       "1382  0.0  0.000000  0.0  0.009143  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "6851  0.0  0.000000  0.0  0.005735  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "8584  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3106  0.0  0.000804  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "9648  0.0  0.000790  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "         982_y  983_y  984_y     985_y  986_y  987_y  988_y  989_y  990_y  \\\n",
       "1382  0.003974    0.0    0.0  0.002027    0.0    0.0    0.0    0.0    0.0   \n",
       "6851  0.000000    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
       "8584  0.000000    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
       "3106  0.000000    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
       "9648  0.000000    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      991_y  \n",
       "1382    0.0  \n",
       "6851    0.0  \n",
       "8584    0.0  \n",
       "3106    0.0  \n",
       "9648    0.0  \n",
       "\n",
       "[5 rows x 1984 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "chronic-windows",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T07:22:12.124538Z",
     "start_time": "2021-05-17T07:17:32.344967Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid search\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END .................criterion=gini, n_estimators=2; total time=   0.5s\n",
      "[CV 2/5] END .................criterion=gini, n_estimators=2; total time=   0.4s\n",
      "[CV 3/5] END .................criterion=gini, n_estimators=2; total time=   0.3s\n",
      "[CV 4/5] END .................criterion=gini, n_estimators=2; total time=   0.4s\n",
      "[CV 5/5] END .................criterion=gini, n_estimators=2; total time=   0.4s\n",
      "[CV 1/5] END ................criterion=gini, n_estimators=50; total time=   5.0s\n",
      "[CV 2/5] END ................criterion=gini, n_estimators=50; total time=   4.5s\n",
      "[CV 3/5] END ................criterion=gini, n_estimators=50; total time=   4.3s\n",
      "[CV 4/5] END ................criterion=gini, n_estimators=50; total time=   4.2s\n",
      "[CV 5/5] END ................criterion=gini, n_estimators=50; total time=   4.4s\n",
      "[CV 1/5] END ...............criterion=gini, n_estimators=100; total time=   8.3s\n",
      "[CV 2/5] END ...............criterion=gini, n_estimators=100; total time=   8.1s\n",
      "[CV 3/5] END ...............criterion=gini, n_estimators=100; total time=   8.1s\n",
      "[CV 4/5] END ...............criterion=gini, n_estimators=100; total time=   7.6s\n",
      "[CV 5/5] END ...............criterion=gini, n_estimators=100; total time=   7.6s\n",
      "[CV 1/5] END ...............criterion=gini, n_estimators=150; total time=  11.2s\n",
      "[CV 2/5] END ...............criterion=gini, n_estimators=150; total time=  11.2s\n",
      "[CV 3/5] END ...............criterion=gini, n_estimators=150; total time=  11.6s\n",
      "[CV 4/5] END ...............criterion=gini, n_estimators=150; total time=  11.4s\n",
      "[CV 5/5] END ...............criterion=gini, n_estimators=150; total time=  11.3s\n",
      "[CV 1/5] END ..............criterion=entropy, n_estimators=2; total time=   0.4s\n",
      "[CV 2/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 3/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 4/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 5/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 1/5] END .............criterion=entropy, n_estimators=50; total time=   4.8s\n",
      "[CV 2/5] END .............criterion=entropy, n_estimators=50; total time=   4.9s\n",
      "[CV 3/5] END .............criterion=entropy, n_estimators=50; total time=   5.0s\n",
      "[CV 4/5] END .............criterion=entropy, n_estimators=50; total time=   4.9s\n",
      "[CV 5/5] END .............criterion=entropy, n_estimators=50; total time=   4.9s\n",
      "[CV 1/5] END ............criterion=entropy, n_estimators=100; total time=   9.8s\n",
      "[CV 2/5] END ............criterion=entropy, n_estimators=100; total time=   9.8s\n",
      "[CV 3/5] END ............criterion=entropy, n_estimators=100; total time=   9.6s\n",
      "[CV 4/5] END ............criterion=entropy, n_estimators=100; total time=   9.6s\n",
      "[CV 5/5] END ............criterion=entropy, n_estimators=100; total time=   9.9s\n",
      "[CV 1/5] END ............criterion=entropy, n_estimators=150; total time=  14.4s\n",
      "[CV 2/5] END ............criterion=entropy, n_estimators=150; total time=  14.4s\n",
      "[CV 3/5] END ............criterion=entropy, n_estimators=150; total time=  14.6s\n",
      "[CV 4/5] END ............criterion=entropy, n_estimators=150; total time=  15.2s\n",
      "[CV 5/5] END ............criterion=entropy, n_estimators=150; total time=  14.5s\n",
      "Best parameters are: {'criterion': 'gini', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "                train_test_split(tfidf_pairs, labels, train_size=0.8, random_state=SEED)\n",
    "acc, f1, auc = predict_RF(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "enabling-nevada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T07:22:12.152659Z",
     "start_time": "2021-05-17T07:22:12.127369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF: 0.5173836181496759 0.5179517363154797 0.501126708122857\n",
      "Random: (0.49616971125515613, 0.48955223880597015, 0.5)\n",
      "Majority: (0.4926340601060695, 0.6600868535333597, 0.5)\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF:\", acc, f1, auc)\n",
    "print(\"Random:\", predict_random(X_train, y_train, X_test, y_test))\n",
    "print(\"Majority:\",predict_majority(X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-government",
   "metadata": {},
   "source": [
    "### song2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fixed-husband",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:02:57.335219Z",
     "start_time": "2021-05-16T21:02:56.236032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8485\n",
      "8485\n"
     ]
    }
   ],
   "source": [
    "s2v_pairs = create_vectors_pairs(s2v_df, song_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "signal-theory",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:02:57.392678Z",
     "start_time": "2021-05-16T21:02:57.339196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>9_x</th>\n",
       "      <th>...</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "      <th>96_y</th>\n",
       "      <th>97_y</th>\n",
       "      <th>98_y</th>\n",
       "      <th>99_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>0.050536</td>\n",
       "      <td>0.700072</td>\n",
       "      <td>1.502735</td>\n",
       "      <td>0.799808</td>\n",
       "      <td>1.421927</td>\n",
       "      <td>-4.074349</td>\n",
       "      <td>-0.018887</td>\n",
       "      <td>1.857755</td>\n",
       "      <td>-2.008438</td>\n",
       "      <td>-0.825392</td>\n",
       "      <td>...</td>\n",
       "      <td>2.049515</td>\n",
       "      <td>1.042242</td>\n",
       "      <td>-2.304445</td>\n",
       "      <td>-0.645610</td>\n",
       "      <td>1.034146</td>\n",
       "      <td>0.522461</td>\n",
       "      <td>-0.801188</td>\n",
       "      <td>-2.008663</td>\n",
       "      <td>-0.396661</td>\n",
       "      <td>0.024584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>-0.932494</td>\n",
       "      <td>1.682110</td>\n",
       "      <td>-0.600307</td>\n",
       "      <td>1.201052</td>\n",
       "      <td>1.746724</td>\n",
       "      <td>0.416302</td>\n",
       "      <td>-0.009236</td>\n",
       "      <td>0.224624</td>\n",
       "      <td>0.714160</td>\n",
       "      <td>1.807721</td>\n",
       "      <td>...</td>\n",
       "      <td>2.049515</td>\n",
       "      <td>1.042242</td>\n",
       "      <td>-2.304445</td>\n",
       "      <td>-0.645610</td>\n",
       "      <td>1.034146</td>\n",
       "      <td>0.522461</td>\n",
       "      <td>-0.801188</td>\n",
       "      <td>-2.008663</td>\n",
       "      <td>-0.396661</td>\n",
       "      <td>0.024584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>0.050536</td>\n",
       "      <td>0.700072</td>\n",
       "      <td>1.502735</td>\n",
       "      <td>0.799808</td>\n",
       "      <td>1.421927</td>\n",
       "      <td>-4.074349</td>\n",
       "      <td>-0.018887</td>\n",
       "      <td>1.857755</td>\n",
       "      <td>-2.008438</td>\n",
       "      <td>-0.825392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072537</td>\n",
       "      <td>-0.068162</td>\n",
       "      <td>-1.121787</td>\n",
       "      <td>-0.130818</td>\n",
       "      <td>-0.168337</td>\n",
       "      <td>-0.234738</td>\n",
       "      <td>-0.270714</td>\n",
       "      <td>-0.263553</td>\n",
       "      <td>-0.453970</td>\n",
       "      <td>-0.143811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>-0.885090</td>\n",
       "      <td>3.123382</td>\n",
       "      <td>0.424417</td>\n",
       "      <td>1.275812</td>\n",
       "      <td>1.166315</td>\n",
       "      <td>-1.786570</td>\n",
       "      <td>-1.911305</td>\n",
       "      <td>2.292119</td>\n",
       "      <td>-1.925104</td>\n",
       "      <td>1.388782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514146</td>\n",
       "      <td>-0.032140</td>\n",
       "      <td>-0.602289</td>\n",
       "      <td>-0.052574</td>\n",
       "      <td>-0.092585</td>\n",
       "      <td>-0.073549</td>\n",
       "      <td>-0.129805</td>\n",
       "      <td>-0.187154</td>\n",
       "      <td>-0.227991</td>\n",
       "      <td>-0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>-0.885090</td>\n",
       "      <td>3.123382</td>\n",
       "      <td>0.424417</td>\n",
       "      <td>1.275812</td>\n",
       "      <td>1.166315</td>\n",
       "      <td>-1.786570</td>\n",
       "      <td>-1.911305</td>\n",
       "      <td>2.292119</td>\n",
       "      <td>-1.925104</td>\n",
       "      <td>1.388782</td>\n",
       "      <td>...</td>\n",
       "      <td>1.174746</td>\n",
       "      <td>0.092594</td>\n",
       "      <td>-3.189829</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>-0.239225</td>\n",
       "      <td>1.520638</td>\n",
       "      <td>0.963496</td>\n",
       "      <td>-1.337876</td>\n",
       "      <td>-1.011305</td>\n",
       "      <td>0.964345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0_x       1_x       2_x       3_x       4_x       5_x       6_x  \\\n",
       "2416  0.050536  0.700072  1.502735  0.799808  1.421927 -4.074349 -0.018887   \n",
       "3249 -0.932494  1.682110 -0.600307  1.201052  1.746724  0.416302 -0.009236   \n",
       "2532  0.050536  0.700072  1.502735  0.799808  1.421927 -4.074349 -0.018887   \n",
       "1651 -0.885090  3.123382  0.424417  1.275812  1.166315 -1.786570 -1.911305   \n",
       "4873 -0.885090  3.123382  0.424417  1.275812  1.166315 -1.786570 -1.911305   \n",
       "\n",
       "           7_x       8_x       9_x  ...      90_y      91_y      92_y  \\\n",
       "2416  1.857755 -2.008438 -0.825392  ...  2.049515  1.042242 -2.304445   \n",
       "3249  0.224624  0.714160  1.807721  ...  2.049515  1.042242 -2.304445   \n",
       "2532  1.857755 -2.008438 -0.825392  ...  1.072537 -0.068162 -1.121787   \n",
       "1651  2.292119 -1.925104  1.388782  ...  0.514146 -0.032140 -0.602289   \n",
       "4873  2.292119 -1.925104  1.388782  ...  1.174746  0.092594 -3.189829   \n",
       "\n",
       "          93_y      94_y      95_y      96_y      97_y      98_y      99_y  \n",
       "2416 -0.645610  1.034146  0.522461 -0.801188 -2.008663 -0.396661  0.024584  \n",
       "3249 -0.645610  1.034146  0.522461 -0.801188 -2.008663 -0.396661  0.024584  \n",
       "2532 -0.130818 -0.168337 -0.234738 -0.270714 -0.263553 -0.453970 -0.143811  \n",
       "1651 -0.052574 -0.092585 -0.073549 -0.129805 -0.187154 -0.227991 -0.060000  \n",
       "4873  0.784431 -0.239225  1.520638  0.963496 -1.337876 -1.011305  0.964345  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2v_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "accessory-trunk",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:08:09.918249Z",
     "start_time": "2021-05-16T21:02:57.397659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid search\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END .................criterion=gini, n_estimators=2; total time=   0.2s\n",
      "[CV 2/5] END .................criterion=gini, n_estimators=2; total time=   0.2s\n",
      "[CV 3/5] END .................criterion=gini, n_estimators=2; total time=   0.2s\n",
      "[CV 4/5] END .................criterion=gini, n_estimators=2; total time=   0.2s\n",
      "[CV 5/5] END .................criterion=gini, n_estimators=2; total time=   0.2s\n",
      "[CV 1/5] END ................criterion=gini, n_estimators=50; total time=   3.8s\n",
      "[CV 2/5] END ................criterion=gini, n_estimators=50; total time=   3.6s\n",
      "[CV 3/5] END ................criterion=gini, n_estimators=50; total time=   3.9s\n",
      "[CV 4/5] END ................criterion=gini, n_estimators=50; total time=   3.7s\n",
      "[CV 5/5] END ................criterion=gini, n_estimators=50; total time=   3.8s\n",
      "[CV 1/5] END ...............criterion=gini, n_estimators=100; total time=   7.4s\n",
      "[CV 2/5] END ...............criterion=gini, n_estimators=100; total time=   7.6s\n",
      "[CV 3/5] END ...............criterion=gini, n_estimators=100; total time=   7.6s\n",
      "[CV 4/5] END ...............criterion=gini, n_estimators=100; total time=   7.5s\n",
      "[CV 5/5] END ...............criterion=gini, n_estimators=100; total time=   7.9s\n",
      "[CV 1/5] END ...............criterion=gini, n_estimators=150; total time=  11.4s\n",
      "[CV 2/5] END ...............criterion=gini, n_estimators=150; total time=  10.6s\n",
      "[CV 3/5] END ...............criterion=gini, n_estimators=150; total time=  10.2s\n",
      "[CV 4/5] END ...............criterion=gini, n_estimators=150; total time=  10.6s\n",
      "[CV 5/5] END ...............criterion=gini, n_estimators=150; total time=  10.8s\n",
      "[CV 1/5] END ..............criterion=entropy, n_estimators=2; total time=   0.2s\n",
      "[CV 2/5] END ..............criterion=entropy, n_estimators=2; total time=   0.2s\n",
      "[CV 3/5] END ..............criterion=entropy, n_estimators=2; total time=   0.2s\n",
      "[CV 4/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 5/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 1/5] END .............criterion=entropy, n_estimators=50; total time=   5.7s\n",
      "[CV 2/5] END .............criterion=entropy, n_estimators=50; total time=   5.9s\n",
      "[CV 3/5] END .............criterion=entropy, n_estimators=50; total time=   5.9s\n",
      "[CV 4/5] END .............criterion=entropy, n_estimators=50; total time=   5.9s\n",
      "[CV 5/5] END .............criterion=entropy, n_estimators=50; total time=   6.1s\n",
      "[CV 1/5] END ............criterion=entropy, n_estimators=100; total time=  11.7s\n",
      "[CV 2/5] END ............criterion=entropy, n_estimators=100; total time=  11.5s\n",
      "[CV 3/5] END ............criterion=entropy, n_estimators=100; total time=  11.6s\n",
      "[CV 4/5] END ............criterion=entropy, n_estimators=100; total time=  12.0s\n",
      "[CV 5/5] END ............criterion=entropy, n_estimators=100; total time=  12.6s\n",
      "[CV 1/5] END ............criterion=entropy, n_estimators=150; total time=  17.4s\n",
      "[CV 2/5] END ............criterion=entropy, n_estimators=150; total time=  17.2s\n",
      "[CV 3/5] END ............criterion=entropy, n_estimators=150; total time=  17.4s\n",
      "[CV 4/5] END ............criterion=entropy, n_estimators=150; total time=  17.2s\n",
      "[CV 5/5] END ............criterion=entropy, n_estimators=150; total time=  18.6s\n",
      "Best parameters are: {'criterion': 'entropy', 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "                train_test_split(s2v_pairs, labels, train_size=0.8, random_state=SEED)\n",
    "acc, f1, auc = predict_RF(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "liquid-regulation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:08:09.927828Z",
     "start_time": "2021-05-16T21:08:09.922427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song2Vec: 0.5085444902769594 0.5250569476082005 0.49960822232966007\n"
     ]
    }
   ],
   "source": [
    "print(\"Song2Vec:\", acc, f1, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-trademark",
   "metadata": {},
   "source": [
    "## Same artist classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "analyzed-parcel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:03:44.086375Z",
     "start_time": "2021-05-16T17:03:34.163889Z"
    }
   },
   "outputs": [],
   "source": [
    "discography = songs[[\"artist_name\", \"track_name\", \"song_id\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vocal-adolescent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:03:45.234189Z",
     "start_time": "2021-05-16T17:03:45.195392Z"
    }
   },
   "outputs": [],
   "source": [
    "def pick_songs_from_same_artist(discography, half_n):\n",
    "    \"\"\"Simply chooses random songs pair them with the previous or following one\"\"\"\n",
    "    artist_with_multiple_songs = discography.groupby(\"artist_name\")\\\n",
    "                                .agg(count=(\"track_name\", \"count\")).reset_index()\n",
    "#     print(len(discography.merge(tfidf_df, left_on=\"song_id\", right_index=True)))\n",
    "    discography = discography.merge(artist_with_multiple_songs)\n",
    "    \n",
    "    song_pairs = discography.groupby(\"artist_name\").agg(song1=(\"song_id\", \"first\"), \n",
    "                                                        song2=(\"song_id\", \"last\"))\n",
    "    X = song_pairs.sample(half_n, random_state=SEED).values\n",
    "#     print(len(X))\n",
    "#     print(len(tfidf_df.index.isin(X_pos[:,0])))\n",
    "    y = np.ones(half_n)\n",
    "    return X, y\n",
    "    \n",
    "def pick_songs_from_diff_artist(discography, half_n):\n",
    "    discography = discography.drop_duplicates(\"artist_name\")\n",
    "    songs = discography.sample(2*half_n, random_state=SEED).song_id.values\n",
    "    songs1 = songs[:half_n]\n",
    "    songs2 = songs[half_n:]\n",
    "    X = np.c_[songs1, songs2]\n",
    "    y = np.zeros(half_n)\n",
    "    return X, y\n",
    "\n",
    "def create_artist_dataset(discography, n=20000):\n",
    "    \"\"\"Create a dataset of song pairs that either appeared in the same context or not\"\"\" \n",
    "    discography = discography.merge(s2v_df, left_on=\"song_id\", right_index=True)\n",
    "    discography = discography.merge(tfidf_df, left_on=\"song_id\", right_index=True)\n",
    "    X_pos, y_pos = pick_songs_from_same_artist(discography, n//2)\n",
    "    X_neg, y_neg = pick_songs_from_diff_artist(discography, n//2)\n",
    "#     print(len(tfidf_df))\n",
    "#     print(sum(tfidf_df.index.isin(X_pos[:,0])))\n",
    "#     print(sum(tfidf_df.index.isin(X_pos[:,1])))\n",
    "    old_X = np.r_[X_pos, X_neg]\n",
    "    old_y = np.r_[y_pos, y_neg]\n",
    "    dataset = list(zip(old_X, old_y))\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(dataset)\n",
    "    X, y = zip(*dataset)\n",
    "    return pd.DataFrame(X, columns=[\"song1\", \"song2\"]), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-content",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-17T07:56:48.819Z"
    }
   },
   "outputs": [],
   "source": [
    "song_pairs, labels = create_artist_dataset(discography, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-collar",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-17T07:56:49.264Z"
    }
   },
   "outputs": [],
   "source": [
    "#Only keep song with s2v embeddings\n",
    "song_pairs = song_pairs.copy()\n",
    "song_pairs['labels'] = labels\n",
    "song_pairs = song_pairs[song_pairs.song1.isin(s2v_df.index) & song_pairs.song2.isin(s2v_df.index)]\n",
    "song_pairs = song_pairs[song_pairs.song1.isin(tfidf_df.index) & song_pairs.song2.isin(tfidf_df.index)]\n",
    "labels = song_pairs.labels\n",
    "# song_pairs.drop('labels', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "engaging-showcase",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T07:54:54.234352Z",
     "start_time": "2021-05-17T07:54:54.178588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13547 3547.0\n"
     ]
    }
   ],
   "source": [
    "print(len(labels), sum(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-trinidad",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "scientific-lewis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T07:52:07.023106Z",
     "start_time": "2021-05-17T07:51:51.030060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6774\n",
      "6774\n"
     ]
    }
   ],
   "source": [
    "tfidf_pairs = create_vectors_pairs(tfidf_df, song_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "existing-tuesday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T07:52:07.161495Z",
     "start_time": "2021-05-17T07:52:07.029452Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "                train_test_split(tfidf_pairs, labels, train_size=0.8, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aggregate-passing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T20:57:45.521299Z",
     "start_time": "2021-05-16T20:51:23.657223Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid search\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END .................criterion=gini, n_estimators=2; total time=   0.4s\n",
      "[CV 2/5] END .................criterion=gini, n_estimators=2; total time=   0.4s\n",
      "[CV 3/5] END .................criterion=gini, n_estimators=2; total time=   0.4s\n",
      "[CV 4/5] END .................criterion=gini, n_estimators=2; total time=   0.3s\n",
      "[CV 5/5] END .................criterion=gini, n_estimators=2; total time=   0.4s\n",
      "[CV 1/5] END ................criterion=gini, n_estimators=50; total time=   7.8s\n",
      "[CV 2/5] END ................criterion=gini, n_estimators=50; total time=   6.7s\n",
      "[CV 3/5] END ................criterion=gini, n_estimators=50; total time=   7.6s\n",
      "[CV 4/5] END ................criterion=gini, n_estimators=50; total time=   9.2s\n",
      "[CV 5/5] END ................criterion=gini, n_estimators=50; total time=   7.8s\n",
      "[CV 1/5] END ...............criterion=gini, n_estimators=100; total time=  13.6s\n",
      "[CV 2/5] END ...............criterion=gini, n_estimators=100; total time=  13.7s\n",
      "[CV 3/5] END ...............criterion=gini, n_estimators=100; total time=  14.6s\n",
      "[CV 4/5] END ...............criterion=gini, n_estimators=100; total time=  13.0s\n",
      "[CV 5/5] END ...............criterion=gini, n_estimators=100; total time=  15.0s\n",
      "[CV 1/5] END ...............criterion=gini, n_estimators=150; total time=  21.5s\n",
      "[CV 2/5] END ...............criterion=gini, n_estimators=150; total time=  18.2s\n",
      "[CV 3/5] END ...............criterion=gini, n_estimators=150; total time=  18.6s\n",
      "[CV 4/5] END ...............criterion=gini, n_estimators=150; total time=  17.9s\n",
      "[CV 5/5] END ...............criterion=gini, n_estimators=150; total time=  17.6s\n",
      "[CV 1/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 2/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 3/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 4/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 5/5] END ..............criterion=entropy, n_estimators=2; total time=   0.3s\n",
      "[CV 1/5] END .............criterion=entropy, n_estimators=50; total time=   5.3s\n",
      "[CV 2/5] END .............criterion=entropy, n_estimators=50; total time=   5.1s\n",
      "[CV 3/5] END .............criterion=entropy, n_estimators=50; total time=   5.0s\n",
      "[CV 4/5] END .............criterion=entropy, n_estimators=50; total time=   5.0s\n",
      "[CV 5/5] END .............criterion=entropy, n_estimators=50; total time=   5.3s\n",
      "[CV 1/5] END ............criterion=entropy, n_estimators=100; total time=  10.0s\n",
      "[CV 2/5] END ............criterion=entropy, n_estimators=100; total time=  10.0s\n",
      "[CV 3/5] END ............criterion=entropy, n_estimators=100; total time=   9.9s\n",
      "[CV 4/5] END ............criterion=entropy, n_estimators=100; total time=  10.0s\n",
      "[CV 5/5] END ............criterion=entropy, n_estimators=100; total time=  10.2s\n",
      "[CV 1/5] END ............criterion=entropy, n_estimators=150; total time=  14.8s\n",
      "[CV 2/5] END ............criterion=entropy, n_estimators=150; total time=  14.9s\n",
      "[CV 3/5] END ............criterion=entropy, n_estimators=150; total time=  14.8s\n",
      "[CV 4/5] END ............criterion=entropy, n_estimators=150; total time=  14.8s\n",
      "[CV 5/5] END ............criterion=entropy, n_estimators=150; total time=  15.7s\n",
      "Best parameters are: {'criterion': 'gini', 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "                train_test_split(tfidf_pairs, labels, train_size=0.8, random_state=SEED)\n",
    "acc, f1, auc = predict_RF(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "psychological-corporation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T20:57:45.540152Z",
     "start_time": "2021-05-16T20:57:45.528805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF: 0.6546125461254613 0.13333333333333333 0.4766000294570833\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF:\", acc, f1, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-netscape",
   "metadata": {},
   "source": [
    "### Song2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "radical-veteran",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T20:57:48.337557Z",
     "start_time": "2021-05-16T20:57:45.545747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6774\n",
      "6774\n"
     ]
    }
   ],
   "source": [
    "s2v_pairs = create_vectors_pairs(s2v_df, song_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "military-processor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:01:53.991079Z",
     "start_time": "2021-05-16T20:57:48.340567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid search\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END .................criterion=gini, n_estimators=2; total time=   0.1s\n",
      "[CV 2/5] END .................criterion=gini, n_estimators=2; total time=   0.2s\n",
      "[CV 3/5] END .................criterion=gini, n_estimators=2; total time=   0.1s\n",
      "[CV 4/5] END .................criterion=gini, n_estimators=2; total time=   0.1s\n",
      "[CV 5/5] END .................criterion=gini, n_estimators=2; total time=   0.2s\n",
      "[CV 1/5] END ................criterion=gini, n_estimators=50; total time=   3.1s\n",
      "[CV 2/5] END ................criterion=gini, n_estimators=50; total time=   3.3s\n",
      "[CV 3/5] END ................criterion=gini, n_estimators=50; total time=   3.3s\n",
      "[CV 4/5] END ................criterion=gini, n_estimators=50; total time=   3.6s\n",
      "[CV 5/5] END ................criterion=gini, n_estimators=50; total time=   3.3s\n",
      "[CV 1/5] END ...............criterion=gini, n_estimators=100; total time=   6.1s\n",
      "[CV 2/5] END ...............criterion=gini, n_estimators=100; total time=   6.3s\n",
      "[CV 3/5] END ...............criterion=gini, n_estimators=100; total time=   6.0s\n",
      "[CV 4/5] END ...............criterion=gini, n_estimators=100; total time=   7.8s\n",
      "[CV 5/5] END ...............criterion=gini, n_estimators=100; total time=   6.6s\n",
      "[CV 1/5] END ...............criterion=gini, n_estimators=150; total time=  10.4s\n",
      "[CV 2/5] END ...............criterion=gini, n_estimators=150; total time=  10.2s\n",
      "[CV 3/5] END ...............criterion=gini, n_estimators=150; total time=  11.2s\n",
      "[CV 4/5] END ...............criterion=gini, n_estimators=150; total time=  11.2s\n",
      "[CV 5/5] END ...............criterion=gini, n_estimators=150; total time=  10.0s\n",
      "[CV 1/5] END ..............criterion=entropy, n_estimators=2; total time=   0.2s\n",
      "[CV 2/5] END ..............criterion=entropy, n_estimators=2; total time=   0.2s\n",
      "[CV 3/5] END ..............criterion=entropy, n_estimators=2; total time=   0.2s\n",
      "[CV 4/5] END ..............criterion=entropy, n_estimators=2; total time=   0.2s\n",
      "[CV 5/5] END ..............criterion=entropy, n_estimators=2; total time=   0.2s\n",
      "[CV 1/5] END .............criterion=entropy, n_estimators=50; total time=   5.5s\n",
      "[CV 2/5] END .............criterion=entropy, n_estimators=50; total time=   4.9s\n",
      "[CV 3/5] END .............criterion=entropy, n_estimators=50; total time=   4.5s\n",
      "[CV 4/5] END .............criterion=entropy, n_estimators=50; total time=   4.8s\n",
      "[CV 5/5] END .............criterion=entropy, n_estimators=50; total time=   4.6s\n",
      "[CV 1/5] END ............criterion=entropy, n_estimators=100; total time=   9.6s\n",
      "[CV 2/5] END ............criterion=entropy, n_estimators=100; total time=  10.0s\n",
      "[CV 3/5] END ............criterion=entropy, n_estimators=100; total time=   9.1s\n",
      "[CV 4/5] END ............criterion=entropy, n_estimators=100; total time=   9.3s\n",
      "[CV 5/5] END ............criterion=entropy, n_estimators=100; total time=   8.5s\n",
      "[CV 1/5] END ............criterion=entropy, n_estimators=150; total time=  14.7s\n",
      "[CV 2/5] END ............criterion=entropy, n_estimators=150; total time=  14.9s\n",
      "[CV 3/5] END ............criterion=entropy, n_estimators=150; total time=  12.9s\n",
      "[CV 4/5] END ............criterion=entropy, n_estimators=150; total time=  13.8s\n",
      "[CV 5/5] END ............criterion=entropy, n_estimators=150; total time=  14.1s\n",
      "Best parameters are: {'criterion': 'gini', 'n_estimators': 2}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "                train_test_split(s2v_pairs, labels, train_size=0.8, random_state=SEED)\n",
    "acc, f1, auc = predict_RF(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "frozen-marsh",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:01:54.003331Z",
     "start_time": "2021-05-16T21:01:53.994876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song2Vec: 0.7070110701107011 0.13507625272331156 0.5006755302274993\n"
     ]
    }
   ],
   "source": [
    "print(\"Song2Vec:\", acc, f1, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "latter-criminal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T21:01:54.041693Z",
     "start_time": "2021-05-16T21:01:54.006819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random: (0.5003690036900369, 0.34079844206426485, 0.5)\n",
      "Majority: (0.7402214022140221, 0.0, 0.5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Random:\", predict_random(X_train, y_train, X_test, y_test))\n",
    "print(\"Majority:\",predict_majority(X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-experience",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbd",
   "language": "python",
   "name": "mlbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
